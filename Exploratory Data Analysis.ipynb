{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # to get \"unresolved\" packages\n",
    "sys.path.append(\"/Users/a1765262/opt/anaconda3/lib/python3.9/site-packages\")\n",
    "\n",
    "import pandas as pd # for data frames\n",
    "import os # for working directories\n",
    "import numpy as np # for numbers\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from corextopic import corextopic as ct # for topic model\n",
    "import string # for preprocessing\n",
    "import sklearn.feature_extraction.text # for vectoriser\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer # for sentiment\n",
    "import pickle\n",
    "import scipy\n",
    "from nltk import FreqDist\n",
    "import shifterator as sh\n",
    "import datetime\n",
    "# from readability import readability\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "sys.path.append(\"./Other\")\n",
    "import irulan\n",
    "\n",
    "channel_list = [\"ABC1\", \"Ch7\", \"Ch9\", \"Ch10\", \"SBS\", \"ABC24\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the total number of words, and the number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pickle.load(open(\"./Data/2022_all_clean_split.pkl\", \"rb\"))\n",
    "\n",
    "for channel in channel_list:    \n",
    "\n",
    "    text = \" \".join(text[channel]).split()\n",
    "    print(f\"Total number of words ({channel}):\", len(text))\n",
    "    print(f\"Number of unique words ({channel}):\", len(set(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the number of unique programs, and the number of genres in each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in channel_list:\n",
    "\n",
    "    data = pd.read_csv(f'./Data/{channel}_2022.csv')\n",
    "\n",
    "    print(f\"Number of individual programs ({channel}):\", len(set(data[\"program\"])))\n",
    "    print(f\"Number of genres ({channel}):\", len(set(data[\"genre\"])))\n",
    "    print(text.groupby(\"genre\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the terms with the greatest difference in Tsallis entropy on each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = pickle.load(open(\"./Data/2022_all_clean_split.pkl\", \"rb\"))\n",
    "\n",
    "all_text_for_counts = all_text[0][:]\n",
    "\n",
    "for i in range(1, 6):\n",
    "    all_text_for_counts.extend(all_text[i])\n",
    "\n",
    "all_text_for_counts = \" \".join(all_text_for_counts)\n",
    "\n",
    "all_counts = dict() # initialise dictionary\n",
    "# get frequency counts\n",
    "all_counts = FreqDist(all_text_for_counts.split())\n",
    "\n",
    "for i, channel in enumerate(channel_list):\n",
    "\n",
    "    text = \" \".join(all_text[i])\n",
    "\n",
    "    channel_counts = dict() # initialise dictionary\n",
    "    # get frequency counts\n",
    "    channel_counts = FreqDist(text.split())\n",
    "    \n",
    "\n",
    "    entropy_shift = sh.EntropyShift(type2freq_1=all_counts,\n",
    "                                    type2freq_2=channel_counts,\n",
    "                                    alpha = 0.3)\n",
    "    \n",
    "    print(entropy_shift.get_shift_scores())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
