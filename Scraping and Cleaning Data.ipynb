{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook details the method for obtaining data from the Tveeder API and converting it into an easy format for us to work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "# import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "#vectorising channels\n",
    "# for the text\n",
    "channel_list = ['ABC24','ABC1','Ch10','Ch9','Ch7','SBS']\n",
    "channel_codes = {'ABC24':\"560\",'ABC1':\"561\",'Ch10':\"1589\",'Ch9':\"1072\",'Ch7':\"1328\",'SBS':\"785\"}\n",
    "# for the programs\n",
    "channel_list_2 = ['ABC News 24','ABC 1','Ten Digital','Nine Digital','7 Digital','SBS One']\n",
    "channel_codes_2 = {'ABC News 24':\"560\",'ABC 1':\"561\",'Ten Digital':\"1589\",'Nine Digital':\"1072\",'7 Digital':\"1328\",'SBS One':\"785\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we obtain a month of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from Benjamin Lang, Alexandra Stephenson, Tyson Rowe, and Niamh Jones\n",
    "\n",
    "def monthly_update(month, year):\n",
    "\n",
    "    month = str(month)\n",
    "    month = month.rjust(2,'0')\n",
    "    year = str(year)\n",
    "\n",
    "    \"\"\"\n",
    "    Upload one month's worth of data to Box\n",
    "    \"\"\"\n",
    "\n",
    "    DST_back = ['2015-04-05','2016-04-03','2017-04-02','2018-04-01','2019-04-07','2020-04-05','2021-04-04', '2022-04-03', '2023-04-02']\n",
    "    DST_fwd = ['2015-10-04','2016-10-02','2017-10-01','2018-10-07','2019-10-06','2020-10-04','2021-10-03', '2022-10-02', '2023-10-01']\n",
    "    \n",
    "\n",
    "    # loop through all channels\n",
    "    for channel, channel_prog in zip(channel_list, channel_list_2):\n",
    "\n",
    "        clock_back = 0\n",
    "        clock_fwd = 0\n",
    "\n",
    "        #Getting start and end dates\n",
    "        first = year + \"-\" + month + \"-01\"\n",
    "        firstday = datetime.datetime.strptime(first, \"%Y-%m-%d\")\n",
    "        lastday = firstday + relativedelta(months=1)\n",
    "\n",
    "        #convert time to epoch time, and get start and endtime of day\n",
    "        starttime = firstday.timestamp()\n",
    "        endtime = lastday.timestamp()\n",
    "\n",
    "        #Will loop through each day of the month\n",
    "        start_hour = starttime\n",
    "        end_hour = starttime + 3600\n",
    "\n",
    "        #determine days in month by dividing time by seconds in day\n",
    "        for j in range(1,round((endtime-starttime)/(3600*24))+1):\n",
    "            day = str(j).rjust(2,'0')\n",
    "            date = year + '-' + month.rjust(2,'0') + '-' + day\n",
    "            if date in DST_back:\n",
    "                clock_back = 1\n",
    "            if date in DST_fwd:\n",
    "                clock_fwd = 1\n",
    "            #Create a folder for day if doesn't already exist\n",
    "            raw_file_loc = './raw/' + channel + '/' + year + '/' + date\n",
    "            if not os.path.exists(raw_file_loc):\n",
    "                os.makedirs(raw_file_loc)\n",
    "            text_file_loc = './text/' + channel + '/' + year + '/' + date\n",
    "            if not os.path.exists(text_file_loc):\n",
    "                os.makedirs(text_file_loc)\n",
    "\n",
    "                \n",
    "            #will loop through that day and save files for each hour\n",
    "            i=0\n",
    "            while i in range(24):\n",
    "                #get date and time info\n",
    "                date_time = datetime.datetime.fromtimestamp(start_hour)\n",
    "                time_stamp = date_time.strftime(\"%Y-%m-%d_%H\")\n",
    "                #write file path names\n",
    "                raw_label = str(time_stamp) + \".json\"\n",
    "                text_label = str(time_stamp) + \".txt\"\n",
    "\n",
    "                #account for daylight savings\n",
    "                if clock_back == 1 and i == 3:\n",
    "                    raw_label = str(time_stamp) + \"_DST\" + \".json\"\n",
    "                    text_label = str(time_stamp) + \"_DST\" + \".txt\"\n",
    "                    i=2\n",
    "                    clock_back = 0 \n",
    "                if clock_fwd == 1 and i == 2:\n",
    "                    i=3\n",
    "                    clock_fwd = 0\n",
    "\n",
    "                #obtain file from tveeder\n",
    "                req = requests.get(\"http://beta.tveeder.com/api/channel/\" + channel_codes[channel] + \"/range/\" + str(start_hour) + \"/\" + str(end_hour))\n",
    "                # put text into one string\n",
    "                text = \"\"\n",
    "                for item in req.json()['range']:\n",
    "                #     print(item['text'])\n",
    "                    text += ' '\n",
    "                    text += item['text']\n",
    "            \n",
    "                #save json file\n",
    "                data = req.json()\n",
    "                #os.chdir(raw_file_loc)\n",
    "                with open(raw_file_loc + '/' + raw_label, 'w') as file_raw:\n",
    "                    json.dump(data, file_raw)\n",
    "                #save text file \n",
    "                #os.chdir(text_file_loc)\n",
    "                with open(text_file_loc + '/' + text_label, 'w') as file_text:\n",
    "                    file_text.write(text)    \n",
    "\n",
    "                #change time for next hour\n",
    "                start_hour, end_hour = end_hour, end_hour + 3600\n",
    "                i+=1\n",
    "\n",
    "        # program data\n",
    "\n",
    "        file_loc = './Program schedule (raw)/' + channel_prog + '/' + year\n",
    "        if not os.path.exists(file_loc):\n",
    "                os.makedirs(file_loc)\n",
    "        \n",
    "        #Getting start and end dates for the month\n",
    "        first = year + \"-\" + month + \"-01\"\n",
    "        firstday = datetime.datetime.strptime(first, \"%Y-%m-%d\")\n",
    "        lastday = firstday + relativedelta(months=1)\n",
    "\n",
    "        #convert time to epoch time, and get start and endtime of day\n",
    "        starttime = firstday.timestamp()\n",
    "        endtime = lastday.timestamp()\n",
    "        \n",
    "        #Will loop through each day of the month\n",
    "        startday = starttime - 60*60 #since based on VIC/NSW time\n",
    "        endday = startday + 3600*24\n",
    "        \n",
    "        #determine days in month by dividing time by seconds in day\n",
    "        for j in range(1,round((endtime-starttime)/(3600*24))+1):\n",
    "            day = str(j).rjust(2,'0')\n",
    "            date = year + '-' + month.rjust(2,'0') + '-' + day\n",
    "            \n",
    "            #account for DST\n",
    "            if date in DST_back: #add an hour for DST ending (bckwd)\n",
    "                endday = endday + 3600\n",
    "            elif date in DST_fwd:\n",
    "                endday = endday - 3600\n",
    "            \n",
    "            #collecting programs\n",
    "            req = requests.get(\"http://beta.tveeder.com/api/channel/\" + channel_codes_2[channel_prog] + \"/epg/\" + str(endday))\n",
    "            \n",
    "            # update the working directory\n",
    "            #os.chdir(file_loc)3\n",
    "            \n",
    "            # save json file\n",
    "            with open(file_loc + '/' + str(date) + \".json\", \"w\") as json_file:\n",
    "                json.dump(req.json()['epg'], json_file)\n",
    "                \n",
    "            # update start and end of days\n",
    "            startday = endday\n",
    "            endday = startday + 3600*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage\n",
    "\n",
    "monthly_update(1, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now combine program information with text and filter down to just the text, date, program, and genre\n",
    "\n",
    "from 5 minute docs\n",
    "\n",
    "check this again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(channel1, channel2, year, m1, m2, comp):\n",
    "\n",
    "    \n",
    "\n",
    "    if comp == \"mac\":\n",
    "        folder = r\"/Users/a1765262/Library/CloudStorage/Box-Box\"\n",
    "    else:\n",
    "        folder = r\"/Users/irula/Box\"\n",
    "\n",
    "    days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    data_prog = pd.DataFrame()\n",
    "\n",
    "    for month in range(m1, m2+1):\n",
    "        for day in range(1, days[month-1]+1):\n",
    "                if os.path.exists(folder + '/tveeder/program_schedule/' + channel1 + '/' + str(year) + '/' + str(year) + '-' + str(month).zfill(2) + '-' + str(day).zfill(2) + '.csv'): \n",
    "                    df = pd.read_csv(folder + '/tveeder/program_schedule/' + channel1 + '/' + str(year) + '/' + str(year) + '-' + str(month).zfill(2) + '-' + str(day).zfill(2) + '.csv')\n",
    "\n",
    "                    data_prog = pd.concat([data_prog, df], axis=0)\n",
    "\n",
    "    data_prog.reset_index(inplace = True)\n",
    "\n",
    "    with open(folder + '/MPhil_1/AAAProject/Data/' + channel1 + '_data.json', 'r') as datafile:\n",
    "        datafile = json.load(datafile)\n",
    "        data_capt = json.loads(datafile)\n",
    "        data_capt = pd.DataFrame({'text': data_capt.get('text'), 'date': data_capt.get('date')})\n",
    "\n",
    "    text = [\"0\"]\n",
    "    i = 0\n",
    "    doc = 0\n",
    "    date_init = data_capt[\"date\"][0]\n",
    "    dates = [date_init]\n",
    "\n",
    "    # loop through all shows and find their captions    \n",
    "    for show in range(len(data_prog)): \n",
    "\n",
    "        if show != len(data_prog) - 1:\n",
    "\n",
    "            while data_capt[\"date\"][i] <= data_prog[\"start_epoch\"][show+1]: # while the current captions are earlier than the start of the next show \n",
    "\n",
    "                if data_capt[\"date\"][i] - date_init > 300: # if more than 5 minutes\n",
    "                    doc += 1\n",
    "                    text.append(\"0\")\n",
    "                    date_init = data_capt[\"date\"][i]\n",
    "                    dates = np.append(dates, date_init)\n",
    "\n",
    "                if data_capt[\"date\"][i] >= data_prog[\"start_epoch\"][show] and data_capt[\"date\"][i] <= data_prog[\"end_epoch\"][show]: # ensure the captions are within the show\n",
    "                    text[doc] = text[doc] + \" \" + data_capt[\"text\"][i] # add current line to the show's text\n",
    "                    i += 1 # next line of captions\n",
    "                else:\n",
    "                    i += 1 # next line of captions even if not in current show\n",
    "                if i >= len(data_capt):\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            while data_capt[\"date\"][i] <= data_prog[\"end_epoch\"][show]: # while current captions are earlier than the end of the final show\n",
    "\n",
    "                if data_capt[\"date\"][i] - date_init > 300: # if more than 5 minutes\n",
    "                    doc += 1\n",
    "                    text.append(\"0\")\n",
    "                    date_init = data_capt[\"date\"][i]\n",
    "                    dates = np.append(dates, date_init)\n",
    "\n",
    "                if data_capt[\"date\"][i] >= data_prog[\"start_epoch\"][show] and data_capt[\"date\"][i] <= data_prog[\"end_epoch\"][show]: # ensure the captions are within the show\n",
    "                    text[doc] = text[doc] + \" \" + data_capt[\"text\"][i] # add current line to the show's text\n",
    "                    i += 1 # next line of captions\n",
    "                else:\n",
    "                    i += 1 # next line of captions even if not in current show\n",
    "                if i >= len(data_capt):\n",
    "                    break\n",
    "\n",
    "\n",
    "        doc += 1\n",
    "        text.append(\"0\")\n",
    "        dates = np.append(dates, date_init)\n",
    "\n",
    "    text = [re.sub(\"[^A-Za-z']+\", ' ', str(word)).lower() for word in text] # preprocessing\n",
    "\n",
    "    genres = pd.DataFrame()\n",
    "\n",
    "    for month in range(m1, m2+1):\n",
    "        for day in range(1, days[month-1]+1):\n",
    "                if os.path.exists(folder + '/tveeder/Program schedule (raw)/' + channel2 + '/2022/2022-' + str(month).zfill(2) + '-' + str(day).zfill(2) + '.json'): \n",
    "                    with open(folder + '/tveeder/Program schedule (raw)/' + channel2 + '/2022/2022-' + str(month).zfill(2) + '-' + str(day).zfill(2) + '.json', 'r') as datafile:\n",
    "                        data = json.load(datafile)\n",
    "                        if data:\n",
    "                            data = pd.DataFrame(data)\n",
    "                            genres = pd.concat([genres, data])\n",
    "\n",
    "    genres.reset_index(inplace = True)\n",
    "\n",
    "    # initialise dictionary\n",
    "    genre_dict = dict()\n",
    "\n",
    "    for i in range(len(genres)):\n",
    "        genre_dict[genres[\"title\"][i]] = genres[\"contentinfo\"][i] # make dictionary {title: genre}\n",
    "        \n",
    "    dates = [datetime.datetime.fromtimestamp(dates[i]) for i in range(len(dates))]\n",
    "    \n",
    "    return(dates, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then combine months' worth of data into one data frame spanning 2015-2022.\n",
    "\n",
    "(from Combine Monthly.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list = range(1, 13)\n",
    "year_list = range(2015, 2023)\n",
    "data = pd.DataFrame(columns = ['text', 'date', 'program', 'genre'])\n",
    "\n",
    "'''\n",
    "Loop through each channel, year, and month. \n",
    "We aim to generate a data set for each channel consisting of all text with labels for dates, genre etc.\n",
    "'''\n",
    "\n",
    "for channel in channel_list:\n",
    "\n",
    "    for year in year_list:\n",
    "\n",
    "        for month in month_list:\n",
    "\n",
    "            month = str(month).rjust(2,'0')\n",
    "        \n",
    "            data = pd.concat([data, pd.read_csv(f\"./Data/{channel}_{month}_{year}.csv\")], ignore_index = True)\n",
    "\n",
    "    pd.to_csv(f'./Data/{channel}_all_text.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean and reduce each channel to 5-minute documents. Combine data from all channels into one list for ease of use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_split_mins(data, secs):\n",
    "\n",
    "    # create documents by second to input into a topic model\n",
    "    # input data in the form of a dataframe [text, date]\n",
    "    # output a list split into documents of length [secs]\n",
    "    if len(data) == 0:\n",
    "        return [], []\n",
    "        \n",
    "    # initialise\n",
    "    date0 = data[\"date\"][0]\n",
    "    txt_list = [\"\"]\n",
    "    date_list = [date0]\n",
    "    i = 0\n",
    "\n",
    "    # make into documents of length 'secs'\n",
    "    for text, date in zip(data[\"text\"], data[\"date\"]):\n",
    "\n",
    "        if date - date0 > secs:\n",
    "\n",
    "            txt_list.append(str(text) + \" \")\n",
    "            i += 1\n",
    "            date0 = date\n",
    "            date_list.append(date0)\n",
    "\n",
    "        else:\n",
    "\n",
    "            txt_list[i] += str(text) + \" \"\n",
    "\n",
    "    txt_list = [line.replace(\"'\", \"\").lower() for line in txt_list]\n",
    "\n",
    "    for c in string.punctuation:\n",
    "\n",
    "        txt_list = [line.replace(c, \" \") for line in txt_list]\n",
    "\n",
    "\n",
    "    return txt_list, date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels_text_list = list()\n",
    "all_channels_date_list = list()\n",
    "\n",
    "for channel in channel_list:\n",
    "\n",
    "    # clean data\n",
    "    text_list, date_list = clean_split_mins(data, 300)\n",
    "\n",
    "    # convert from epoch time\n",
    "    date_list = [datetime.datetime.fromtimestamp(date) for date in date_list]\n",
    "\n",
    "    # append each channel to final list\n",
    "    all_channels_text_list.append(text_list)\n",
    "    all_channels_date_list.append(date_list)\n",
    "\n",
    "pickle.dump(all_channels_text_list, open('./Data/all_text.pkl', 'wb'))\n",
    "pickle.dump(all_channels_date_list, open('./Data/all_dates.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From tabled data, select just news text. Clean and reduce to 5-minute documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_news_text = list()\n",
    "all_news_dates = list()\n",
    "\n",
    "for channel in channel_list:\n",
    "\n",
    "    data = pd.read_csv(f'./Data/{channel}_all_text.csv')\n",
    "    \n",
    "    # filter to just one genre\n",
    "    news_data = data[data['genre'] == 'news/current affairs (general)']\n",
    "\n",
    "    # clean data\n",
    "    news_text, news_dates = clean_split_mins(news_data, 300)\n",
    "\n",
    "    # convert from epoch time\n",
    "    news_dates = [datetime.datetime.fromtimestamp(date) for date in news_dates]\n",
    "\n",
    "    all_news_text.append(news_text)\n",
    "    all_news_dates.append(news_dates)\n",
    "\n",
    "pickle.dump(all_news_text, open('./Data/all_news_text.pkl', 'wb'))\n",
    "pickle.dump(all_news_dates, open('./Data/all_news_dates.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
