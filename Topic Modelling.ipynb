{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # to get \"unresolved\" packages\n",
    "sys.path.append(\"/Users/a1765262/opt/anaconda3/lib/python3.9/site-packages\")\n",
    "\n",
    "import pandas as pd # for data frames\n",
    "import os # for working directories\n",
    "import numpy as np # for numbers\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from corextopic import corextopic as ct # for topic model\n",
    "import string # for preprocessing\n",
    "import sklearn.feature_extraction.text # for vectoriser\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer # for sentiment\n",
    "import pickle\n",
    "import scipy\n",
    "from nltk import FreqDist\n",
    "import shifterator as sh\n",
    "import datetime\n",
    "# from readability import readability\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "sys.path.append(\"./Other\")\n",
    "import irulan\n",
    "\n",
    "channel_list = [\"ABC1\", \"Ch7\", \"Ch9\", \"Ch10\", \"SBS\", \"ABC24\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test a topic model anchored on 'sport' for different document lengths. Plot the number of words in each document for 5-minute and program lengths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector of seconds that we will look at (9999 seconds represents the program split)\n",
    "seconds = [10, 60, 120, 300, 600, 1200, 1800, 9999]\n",
    "\n",
    "abc1_2022 = pd.read_csv(\"./Data/ABC1_2022.csv\")\n",
    "\n",
    "for i, s in enumerate(seconds):\n",
    "\n",
    "    # clean text so that documents are s seconds long\n",
    "    text = irulan.clean_split_mins(abc1_2022, s)\n",
    "\n",
    "    # train topic model\n",
    "    _, tm = irulan.tm(text, anchors = ['sport'], num_topics= 40)\n",
    "\n",
    "    print(tm.get_topics()[0])\n",
    "\n",
    "    # if we have split into 5-minute or program-length intervals, make histogram\n",
    "    if s in [60, 9999]:\n",
    "        plt.hist([len(doc.split()) for doc in text], bins = 50)\n",
    "        plt.title(\"The number of words contained in each program\")\n",
    "        plt.xlabel(\"Number of words\")\n",
    "        plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the total correlation of topic models with the number of topics adjusted from 10 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pickle.load(open(\"./Data/2022_all_clean.pkl\", \"rb\"))\n",
    "\n",
    "# make the topic model\n",
    "n_topics = np.array(range(10, 110, 10))\n",
    "iterations = 30\n",
    "tcs = np.empty((len(n_topics), iterations))\n",
    "\n",
    "# initialise vectorizer \n",
    "vectorizer = sklearn.feature_extraction.text.CountVectorizer(max_features = 10000, binary = True) \n",
    "\n",
    "# get sparse matrix of number of times each word appears in each document\n",
    "matrix = vectorizer.fit_transform(text)\n",
    "\n",
    "# get the list of words\n",
    "words = sorted(vectorizer.vocabulary_.keys())\n",
    "\n",
    "for k, n in enumerate(n_topics):\n",
    "    for i in range(iterations):\n",
    "\n",
    "        # train the topic model\n",
    "        tm = ct.Corex(n_hidden = n, words = words, max_iter = 400, seed = i) \n",
    "        tm.fit(matrix, words = words, anchor_strength = 10)\n",
    "\n",
    "        tcs[k, i] = tm.tc\n",
    "        print(f'Value {i} for {n} topics is: {tm.tc}')\n",
    "        del tm\n",
    "\n",
    "# make violin plot\n",
    "plt.violinplot(tcs, positions = np.array(range(10, 110, 10)), widths = 5)\n",
    "plt.title(\"The total correlation of topic models on 2022 data adjusting the number of topics\")\n",
    "plt.ylabel(\"Total correlation\")\n",
    "plt.xlabel(\"Number of topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson and Spearman similarities for topic models with an adjacent number of topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate unsupervised topic models trained on 2022 data from ABC1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 30 topic models with the seed 'sport'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 30 topic models with anchors for each method of inference and calculate Pearson correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare different percentages to subsample with the ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate unsupervised topic models trained on 2022 data for each channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare unsupervised topic models trained on each channel with Pearson similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare anchored topic models trained on each channel with Pearson similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a hierarchical topic model to combine sport topics into one larger overarching sport topic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot media attention for supervised topic models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the coverage bias for some topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get political word counts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate political coverage bias."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
