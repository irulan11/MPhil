{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook replicates word shift graphs for all tables in the thesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shifterator as sh\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "from nltk import FreqDist\n",
    "import irulan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate monthly Tsallis entropy and sentiment shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monthly_shift(text, dates, month, year, lexicon, file_name = None):\n",
    "\n",
    "    # filter to only the text within that month\n",
    "    peak_words = list()\n",
    "    peak = [text[i] for i in range(len(dates)) if dates[i].month == month and dates[i].year == year]\n",
    "\n",
    "    # count words in all of the text\n",
    "    text = \" \".join(text)\n",
    "    counts = dict()\n",
    "    counts = FreqDist(text.split())\n",
    "    del text\n",
    "\n",
    "    # counts words in the peak\n",
    "    peak = \" \".join(peak)\n",
    "    peak_counts = dict()\n",
    "    peak_counts = FreqDist(peak.split())\n",
    "    del peak\n",
    "\n",
    "    # calculate Tsallis entropy shifts\n",
    "    entropy_shift = sh.EntropyShift(type2freq_1=counts,\n",
    "                                        type2freq_2=peak_counts,\n",
    "                                        alpha = 0.3)\n",
    "\n",
    "    # make the shift graph\n",
    "    if file_name:\n",
    "        entropy_shift.get_shift_graph(title=f'Sentiment difference between {month}/{year} and all text',\n",
    "                                    text_size_inset = False,\n",
    "                                    cumulative_inset = False,\n",
    "                                    height = 8,\n",
    "                                    xlabel = 'Score shift',\n",
    "                                    filename = f'{file_name}_entropy.pdf')\n",
    "    else:\n",
    "        entropy_shift.get_shift_graph(title=f'Sentiment difference between {month}/{year} and all text',\n",
    "                                    text_size_inset = False,\n",
    "                                    cumulative_inset = False,\n",
    "                                    height = 8,\n",
    "                                    xlabel = 'Score shift')\n",
    "\n",
    "    # calculate sentiment shifts\n",
    "    sentiment_shift = sh.WeightedAvgShift(type2freq_1=counts,\n",
    "                                    type2freq_2=peak_counts,\n",
    "                                    type2score_1=lexicon,\n",
    "                                    type2score_2=lexicon,\n",
    "                                    reference_value='average')\n",
    "\n",
    "    # make the shift graph\n",
    "    if file_name:\n",
    "        sentiment_shift.get_shift_graph(title=f'Sentiment difference between {month}/{year} and all text',\n",
    "                                    text_size_inset = False,\n",
    "                                    cumulative_inset = False,\n",
    "                                    height = 8,\n",
    "                                    xlabel = 'Score shift',\n",
    "                                    filename = f'{file_name}_sentiment.pdf')\n",
    "    else:\n",
    "        sentiment_shift.get_shift_graph(title=f'Sentiment difference between {month}/{year} and all text',\n",
    "                                text_size_inset = False,\n",
    "                                cumulative_inset = False,\n",
    "                                height = 8,\n",
    "                                xlabel = 'Score shift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel 10/ABC24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Channel 10 and ABC24 text/dates\n",
    "ch10_text = pickle.load(open('all_text.pkl', 'rb'))[3]\n",
    "abc24_text = pickle.load(open('all_text.pkl', 'rb'))[5]\n",
    "ch10_dates = pickle.load(open('all_dates.pkl', 'rb'))[3]\n",
    "abc24_dates = pickle.load(open('all_dates.pkl', 'rb'))[5]\n",
    "nrc_lexicon = pickle.load(open('nrc_lexicon.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'ch10_abc24'\n",
    "\n",
    "# count words in all of the text\n",
    "ch10_text = \" \".join(ch10_text)\n",
    "ch10_counts = dict()\n",
    "ch10_counts = FreqDist(ch10_text.split())\n",
    "del ch10_text\n",
    "\n",
    "# counts words in the peak\n",
    "abc24_text = \" \".join(abc24_text)\n",
    "abc24_counts = dict()\n",
    "abc24_counts = FreqDist(abc24_text.split())\n",
    "del abc24_text\n",
    "\n",
    "# calculate Tsallis entropy shifts\n",
    "entropy_shift = sh.EntropyShift(type2freq_1=ch10_counts,\n",
    "                                    type2freq_2=abc24_counts,\n",
    "                                    alpha = 0.3)\n",
    "\n",
    "# make the shift graph\n",
    "entropy_shift.get_shift_graph(title='Sentiment difference between the Mittens lexicon and the original GloVe lexicon',\n",
    "                            text_size_inset = False,\n",
    "                            cumulative_inset = False,\n",
    "                            height = 8,\n",
    "                            xlabel = 'Score shift',\n",
    "                            filename = f'{file_name}_entropy.pdf')\n",
    "\n",
    "# calculate sentiment shifts\n",
    "sentiment_shift = sh.WeightedAvgShift(type2freq_1 = ch10_counts,\n",
    "                                type2freq_2 = abc24_counts,\n",
    "                                type2score_1 = nrc_lexicon,\n",
    "                                type2score_2 = nrc_lexicon,\n",
    "                                reference_value='average')\n",
    "\n",
    "# make the shift graph\n",
    "sentiment_shift.get_shift_graph(title='Sentiment difference between the Mittens lexicon and the original GloVe lexicon',\n",
    "                            text_size_inset = False,\n",
    "                            cumulative_inset = False,\n",
    "                            height = 8,\n",
    "                            xlabel = 'Score shift',\n",
    "                            filename = f'{file_name}_sentiment.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel 7 all text monthly analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Channel 7 text/dates\n",
    "text = pickle.load(open('all_text.pkl', 'rb'))[1]\n",
    "dates = pickle.load(open('all_dates.pkl', 'rb'))[1]\n",
    "nrc_lexicon = pickle.load(open('nrc_lexicon.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate shifts for each month\n",
    "get_monthly_shift(text, dates, 2, 2018, nrc_lexicon)\n",
    "\n",
    "get_monthly_shift(text, dates, 1, 2020, nrc_lexicon)\n",
    "\n",
    "get_monthly_shift(text, dates, 9, 2022, nrc_lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABC24 news text 2020/2021 and other dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "text = pickle.load(open('all_news.pkl', 'rb'))[5]\n",
    "dates = pickle.load(open('all_news.pkl', 'rb'))[5]\n",
    "nrc_lexicon = pickle.load(open('nrc_lexicon.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'abc24_news_peak'\n",
    "\n",
    "# filter to only the text in 2020/2021\n",
    "peak_words = list()\n",
    "peak = [text[i] for i in range(len(dates)) if dates[i].year == 2020 or dates[i].year == 2021]\n",
    "\n",
    "# count words in all of the text\n",
    "text = \" \".join(text)\n",
    "counts = dict()\n",
    "counts = FreqDist(text.split())\n",
    "del text\n",
    "\n",
    "# counts words in the peak\n",
    "peak = \" \".join(peak)\n",
    "peak_counts = dict()\n",
    "peak_counts = FreqDist(peak.split())\n",
    "del peak\n",
    "\n",
    "# calculate Tsallis entropy shifts\n",
    "entropy_shift = sh.EntropyShift(type2freq_1=counts,\n",
    "                                    type2freq_2=peak_counts,\n",
    "                                    alpha = 0.3)\n",
    "\n",
    "# make the shift graph\n",
    "entropy_shift.get_shift_graph(title='Sentiment difference between the Mittens lexicon and the original GloVe lexicon',\n",
    "                            text_size_inset = False,\n",
    "                            cumulative_inset = False,\n",
    "                            height = 8,\n",
    "                            xlabel = 'Score shift',\n",
    "                            filename = f'{file_name}_entropy.pdf')\n",
    "\n",
    "# calculate sentiment shifts\n",
    "sentiment_shift = sh.WeightedAvgShift(type2freq_1=counts,\n",
    "                                type2freq_2=peak_counts,\n",
    "                                type2score_1=nrc_lexicon,\n",
    "                                type2score_2=nrc_lexicon,\n",
    "                                reference_value='average')\n",
    "\n",
    "# make the shift graph\n",
    "sentiment_shift.get_shift_graph(title='Sentiment difference between the Mittens lexicon and the original GloVe lexicon',\n",
    "                            text_size_inset = False,\n",
    "                            cumulative_inset = False,\n",
    "                            height = 8,\n",
    "                            xlabel = 'Score shift',\n",
    "                            filename = f'{file_name}_sentiment.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Mittens lexicon with NRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "nrc_lexicon = pickle.load(open('nrc_lexicon.pkl', 'rb'))\n",
    "mittens_lexicon = pickle.load(open('mittens_lexicon.pkl', 'rb'))\n",
    "text = pickle.load(open(\"all_text.pkl\", \"rb\"))\n",
    "\n",
    "# get a 10% subsample of data \n",
    "np.random.seed(seed = 0)\n",
    "p = 0.1\n",
    "ints = np.random.randint(0, int(len(text)), int(len(text)*p))\n",
    "text_sampled = [text[i] for i in ints]\n",
    "del text\n",
    "\n",
    "# get the counts of words in the text\n",
    "text_sampled = \" \".join(text_sampled)\n",
    "counts = dict()\n",
    "counts = FreqDist(text_sampled.split())\n",
    "del text_sampled\n",
    "\n",
    "file_name = 'mittens_vs_nrc'\n",
    "\n",
    "# calculate sentiment shifts\n",
    "entropy_shift = sh.EntropyShift(type2freq_1=counts,\n",
    "                                    type2freq_2=peak_counts,\n",
    "                                    alpha = 0.3)\n",
    "\n",
    "entropy_shift.get_shift_graph(title='Entropy difference between the Mittens lexicon and the NRC lexicon',\n",
    "                            text_size_inset = False,\n",
    "                            cumulative_inset = False,\n",
    "                            height = 8,\n",
    "                            xlabel = 'Score shift',\n",
    "                            filename = f'{file_name}_entropy.pdf')\n",
    "\n",
    "# make the shift graph\n",
    "sentiment_shift = sh.WeightedAvgShift(type2freq_1=counts,\n",
    "                                type2freq_2=peak_counts,\n",
    "                                type2score_1=mittens_lexicon,\n",
    "                                type2score_2=mittens_lexicon,\n",
    "                                reference_value='average')\n",
    "\n",
    "\n",
    "sentiment_shift.get_shift_graph(title=f'Sentiment difference between the Mittens lexicon and the NRC lexicon',\n",
    "                                    text_size_inset = False,\n",
    "                                    cumulative_inset = False,\n",
    "                                    height = 8,\n",
    "                                    xlabel = 'Score shift',\n",
    "                                    filename = f'{file_name}_sentiment.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare monthly news text from all channels with Mittens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load news text from all channels\n",
    "text = pickle.load(open('all_news_total.pkl', 'rb'))\n",
    "dates = pickle.load(open('all_news_dates_total.pkl', 'rb'))\n",
    "mittens_lexicon = pickle.load(open('mittens_lexicon.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate shifts for each month\n",
    "get_monthly_shift(text, dates, 1, 2018, mittens_lexicon)\n",
    "\n",
    "get_monthly_shift(text, dates, 4, 2020, mittens_lexicon)\n",
    "\n",
    "get_monthly_shift(text, dates, 10, 2021, mittens_lexicon)\n",
    "\n",
    "get_monthly_shift(text, dates, 3, 2022, mittens_lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the spike in SBS sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SBS news text\n",
    "text = pickle.load(open('all_news_total.pkl', 'rb'))[4]\n",
    "dates = pickle.load(open('all_news_dates_total.pkl', 'rb'))[4]\n",
    "mittens_lexicon = pickle.load(open('mittens_lexicon.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate monthly shifts\n",
    "get_monthly_shift(text, dates, 5, 2022, mittens_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate daily stats\n",
    "mittens_lexicon = pickle.load(open('./Data/nrc_lexicon.pkl', 'rb'))\n",
    "year = 2022\n",
    "month = 5\n",
    "day = 15\n",
    "\n",
    "peak_news = [text[i] for i in range(len(dates)) if dates[i].month == month and dates[i].year == year and dates[i].day == day]\n",
    "del dates\n",
    "\n",
    "text = \" \".join(text)\n",
    "counts = dict()\n",
    "counts = FreqDist(text.split())\n",
    "del text\n",
    "\n",
    "peak_news = \" \".join(peak_news)\n",
    "peak_counts = dict()\n",
    "peak_counts = FreqDist(peak_news.split())\n",
    "\n",
    "entropy_shift = sh.EntropyShift(type2freq_1=counts,\n",
    "                                    type2freq_2=peak_counts,\n",
    "                                    alpha = 0.3)\n",
    "\n",
    "entropy_shift.get_shift_graph(title='Entropy difference between 15/5/2022 SBS text and other',\n",
    "                            text_size_inset = False,\n",
    "                            cumulative_inset = False,\n",
    "                            height = 8,\n",
    "                            xlabel = 'Score shift',\n",
    "                            filename = f'{file_name}_entropy.pdf')\n",
    "\n",
    "sentiment_shift = sh.WeightedAvgShift(type2freq_1=counts,\n",
    "                                type2freq_2=peak_counts,\n",
    "                                type2score_1=mittens_lexicon,\n",
    "                                type2score_2=mittens_lexicon,\n",
    "                                reference_value='average')\n",
    "\n",
    "sentiment_shift.get_shift_graph(title='Sentiment difference between 15/5/2022 SBS text and other',\n",
    "                            text_size_inset = False,\n",
    "                            cumulative_inset = False,\n",
    "                            height = 8,\n",
    "                            xlabel = 'Score shift',\n",
    "                            filename = f'{file_name}_sentiment.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare political 1-minute and 5-minute documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "liberal_text_5_min = pickle.load(open('liberal_text_5_min.pkl', 'rb'))\n",
    "labor_text_5_min = pickle.load(open('labor_text_5_min.pkl', 'rb'))\n",
    "liberal_text_1_min = pickle.load(open('liberal_text_1_min.pkl', 'rb'))\n",
    "labor_text_1_min = pickle.load(open('labor_text_1_min.pkl', 'rb'))\n",
    "\n",
    "# generate counts\n",
    "counts_5_min_liberal, counts_5_min_labor = irulan.get_counts(liberal_text_5_min, labor_text_5_min)\n",
    "counts_1_min_liberal, counts_1_min_labor = irulan.get_counts(liberal_text_1_min, labor_text_1_min)\n",
    "\n",
    "# get and save word shifts\n",
    "entropy_shift = sh.EntropyShift(type2freq_1=counts_1_min_liberal,\n",
    "                                type2freq_2=counts_5_min_liberal,\n",
    "                                alpha = 0.3)\n",
    "\n",
    "entropy_shift.get_shift_graph(system_names = ['1-minute Liberal text', '5-minute Liberal text'],\n",
    "                                title='Entropy difference between 1-minute and 5-minute Liberal text',\n",
    "                                text_size_inset = False,\n",
    "                                cumulative_inset = False,\n",
    "                                top_n = 20,\n",
    "                                height = 8)\n",
    "\n",
    "entropy_shift = sh.EntropyShift(type2freq_1=counts_1_min_labor,\n",
    "                                type2freq_2=counts_5_min_labor,\n",
    "                                alpha = 0.3)\n",
    "\n",
    "entropy_shift.get_shift_graph(system_names = ['1-minute Labor text', '5-minute Labor text'],\n",
    "                                title='Entropy difference between 1-minute and 5-minute Labor text',\n",
    "                                text_size_inset = False,\n",
    "                                cumulative_inset = False,\n",
    "                                top_n = 20,\n",
    "                                height = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare political monthly text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "liberal_text_1_min = pickle.load(open('liberal_text_1_min.pkl', 'rb'))\n",
    "labor_text_1_min = pickle.load(open('labor_text_1_min.pkl', 'rb'))\n",
    "liberal_dates_1_min = pickle.load(open('liberal_dates_1_min.pkl', 'rb'))\n",
    "labor_dates_1_min = pickle.load(open('labor_dates_1_min.pkl', 'rb'))\n",
    "mittens_lexicon = pickle.load(open('mittens_lexicon.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate monthly word shifts\n",
    "get_monthly_shift(liberal_text_1_min, 2, 2021, mittens_lexicon)\n",
    "\n",
    "get_monthly_shift(labor_text_1_min, 9, 2019, mittens_lexicon)\n",
    "\n",
    "get_monthly_shift(labor_text_1_min, 3, 2022, mittens_lexicon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
